{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6w2lXzWWMNa"
   },
   "source": [
    "# **Aula 04 - Regressão pt. 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-NYUKN7WYgC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Para plotar imagens mais bonitinhas\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Para conseguir reproduzir os mesmos resultados \n",
    "np.random.seed(42)\n",
    "\n",
    "#Caminho definido para salvar as imagens\n",
    "#Esse comando só funcionará se você estiver com o Google Drive montado\n",
    "DIR = \"/Aula04_regressao_pt2/\"\n",
    "\n",
    "#Se a pasta ainda não foi criada, então vamos cria-la\n",
    "if not os.path.isdir(DIR):\n",
    "      os.makedirs(DIR)\n",
    "      print(\"Criando pasta\")\n",
    "\n",
    "#Função para salvar as imagens na pasta\n",
    "def salvar_figura(fig_id, tight_layout=True):\n",
    "    path = os.path.join(DIR, fig_id + \".png\")\n",
    "    print(\"Salvando figura\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeblTPnsWoNs"
   },
   "source": [
    "## **Regressão Linear**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6r2EKRnhKoAF"
   },
   "source": [
    "> A Função `rand()` do `numpy` gera valores aleatorios entre 0 e 1. Na célula de códgio abaixo, estamos criando uma matriz 100x1 com valores alteatórios, que ao multiplicarmos por 2, teremos valores entre 0 e 2, mas ainda com uma distribuição uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SsSyTkUHMoCi",
    "outputId": "b1f845c3-6292-4f51-c09a-8bae2e93da0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQbIIS31Iz9I"
   },
   "outputs": [],
   "source": [
    "#Gerar dados sintéticos para X\n",
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "4PMYCIACEbEJ",
    "outputId": "8e94df97-0cdd-41ac-b19f-e2b90441bad9"
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "salvar_figura(\"generated_data_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8SUa5Z-ErFj"
   },
   "outputs": [],
   "source": [
    "#Regressão Linear com Equação Normal\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BsEwQ7bVhBOL",
    "outputId": "bda1c6ba-2a0c-4691-816b-f1ac88e49763"
   },
   "outputs": [],
   "source": [
    "#Adicionando x_0 = 1\n",
    "X_new_b = np.array([[1,0], [1,2]])\n",
    "y_pred = X_new_b.dot(theta_best)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "00wXuH0qhmBy",
    "outputId": "fa912343-76b2-4220-da51-c870d349326e"
   },
   "outputs": [],
   "source": [
    "#Buscando as predições para esses dois valores de x\n",
    "y_pred = X_new_b.dot(theta_best)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "U_rG351DFE8U",
    "outputId": "f524fef7-4144-4b8c-bf00-1075b0f48bb7"
   },
   "outputs": [],
   "source": [
    "plt.plot(X_new_b[:,1], y_pred, \"r-\", linewidth=2, label=\"Predições\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "salvar_figura(\"linear_model_predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49gHexj19WvS"
   },
   "source": [
    "### **Gradiente Descendente para Regressão Linear**\n",
    "> Cada iteração do Gradiente Descendente na vetorial: $$\n",
    "\\theta^{(proximo)} = \\theta - \\alpha \\frac{2}{n}\\bf{X}^T \\cdot (\\bf{X} \\cdot \\theta - \\bf{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "x5DQxpZJ2WNK",
    "outputId": "571e4122-7a61-4a29-cfc7-03b293597dc0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alpha = 0.1 #taxa de aprendizado\n",
    "iteracoes = 2000 # número de iterações até parar.\n",
    "theta = np.random.randn(2,1) #Theta inicial (aleatorio)\n",
    "\n",
    "for i in range(iteracoes):\n",
    "  gradients = 2/X.shape[0] * X_b.T.dot(X_b.dot(theta) - y) #Calculando a derivada parcial da função de erro\n",
    "  theta = theta - alpha * gradients #calculando o restante da operação e atualizando os pesos (theta)\n",
    "  if i % 100 == 0: #a cada 100 iterações, mostrar o valor dos thetas e o erro.\n",
    "    y_pred = X_b.dot(theta)\n",
    "    print(\" Iteração: \", i)\n",
    "    print(f\"theta0: {theta[0,0]} - theta1: {theta[1,0]} --> MSE: {mean_squared_error(y[:,0],y_pred[:,0])}\") \n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_6_KDbswzZ4"
   },
   "source": [
    "**Gradiente Descendente com diferentes taxas de aprendizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCCUA_qTHU0K"
   },
   "outputs": [],
   "source": [
    "theta_path_bgd = []\n",
    "\n",
    "def plot_gradient_descent(theta, alpha, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new_b[:,1], y_predict, style)\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - alpha * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\alpha = {}$\".format(alpha), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "2oYR7IgNwzZx",
    "outputId": "ce893843-586c-47cb-dacb-396993b5b1e3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # inicialização aleatória\n",
    "\n",
    "lista_thetas_bgd = [] #Armazena as predições dos BGDs com diferentes alpha\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131)\n",
    "plot_gradient_descent(theta, alpha=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132)\n",
    "plot_gradient_descent(theta, alpha=0.1, theta_path=lista_thetas_bgd)\n",
    "plt.subplot(133)\n",
    "plot_gradient_descent(theta, alpha=0.5)\n",
    "\n",
    "salvar_figura(\"gradient_descent_plot_diferentes_alfas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAQOSCYnwzZv"
   },
   "source": [
    "### **Stochastic Gradient Descent (SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-42urkeTwzZZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "vBtwzDwNwzZQ",
    "outputId": "f5ceb6e9-0c68-41ff-d883-a9671746b3f6"
   },
   "outputs": [],
   "source": [
    "#Algoritmo SGD\n",
    "\n",
    "# hiperparâmetros - constante1 (t0) e constante2 (t1)\n",
    "\n",
    "# Heurisitica usada para diminuir gradativamente o alpha (taxa de aprendizado)\n",
    "                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxj1sC9AwzZO"
   },
   "source": [
    "> ***Observação:*** \n",
    "  - Por convenção, fazemos rodadas de `n` iteração; cada rodada é chamada de `epoca`. \n",
    "  - Enquanto no BGD executamos 1000 rodadas no código usando todo o dataset, com SGD conseguimos bons resultados apenas com 50 dessas rodadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2W4I1RCkwzYf",
    "outputId": "a0a1aea9-13cf-4412-cfb9-ed80c4ac7e6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "OhynsirgwzXO",
    "outputId": "cf67987a-2e33-414a-ecbb-9c836c3e5f6f"
   },
   "outputs": [],
   "source": [
    "#Usando SGD no sci-kit learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3dKBTJsfG_sX",
    "outputId": "9b060a43-9ed5-4cc0-a6bf-e56901160a9a"
   },
   "outputs": [],
   "source": [
    "#Thethas sci-kit learn\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xucFMmVv6rmb"
   },
   "source": [
    "### **Mini-Batch Gradient Descent (miniBGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ3b6w5lG_sj"
   },
   "outputs": [],
   "source": [
    "lista_thetas_mgd = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FC7riAK0G_sp",
    "outputId": "cfa95cae-353a-4398-aeaa-3e5f8c32b515"
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qKt_spH8_po"
   },
   "source": [
    "### **Comparação GDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNDSAItEG_sv"
   },
   "outputs": [],
   "source": [
    "#Juntando os resultados dos thetas em arrays numpy para plotar a comparação\n",
    "lista_thetas_mgd = np.array(lista_thetas_mgd)\n",
    "lista_thetas_sgd = np.array(lista_thetas_sgd)\n",
    "lista_thetas_bgd = np.array(lista_thetas_bgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "dAeHm26MG_s0",
    "outputId": "fa4b85cf-f323-49be-df04-316e67cc540f"
   },
   "outputs": [],
   "source": [
    "#plotando comparação\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(lista_thetas_sgd[:, 0], lista_thetas_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic\")\n",
    "plt.plot(lista_thetas_mgd[:, 0], lista_thetas_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini-batch\")\n",
    "plt.plot(lista_thetas_bgd[:, 0], lista_thetas_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\n",
    "plt.legend(loc=\"upper left\", fontsize=16)\n",
    "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
    "plt.ylabel(r\"$\\theta_1$   \", fontsize=20, rotation=0)\n",
    "plt.axis([2.5, 4.5, 2.3, 3.9])\n",
    "salvar_figura(\"plot_comparacao_GDs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9mgb-0RMa5t"
   },
   "source": [
    "## **Regressão Polinomial** ##\n",
    "\n",
    "> Primeiro, vamos gerar alguns dados não lineares, com base em uma equação quadrática simples ($y = ax^2 + bx + c$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUmWTdl0Me9R"
   },
   "outputs": [],
   "source": [
    "#Gerando dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "tGcsgc5ISswL",
    "outputId": "01b851f3-c83a-4a82-8cac-dc03610d6c28"
   },
   "outputs": [],
   "source": [
    "#Plotar dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKB1fCySUA8T"
   },
   "source": [
    "> Uma linha reta não seria adequada para esse tipo de distribuição.\n",
    "> Vamos usar a função do Scikit-Learn `PolynomialFeatures` para adicionar graus polinomiais a nossos atributos.\n",
    "> - nesse caso 2ª grau, ou seja, elevar o atributo $x_1$ ao quadrado e adicioná-lo como uma novo atributo $x_2 = x_1^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLvSVEKgSxTQ"
   },
   "outputs": [],
   "source": [
    "#importando poy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hf7aQGoTVBw9"
   },
   "outputs": [],
   "source": [
    "#pegando os atributos polinomiais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3N8oRb9TVPZo",
    "outputId": "549cb7ce-defd-40de-a0e6-cfb534fb2d87"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IM1ZMxwnVrg6"
   },
   "source": [
    "> `X_poly` agora contém o atributo original mais o quadrado desse atributo.\n",
    "> Agora podemos treinar um modelo de regressão linear com esses novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "V-G0D3bWVk8Q",
    "outputId": "d839cb81-3f2f-4166-a63b-884945545bdf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "vXCsgaZvWdpV",
    "outputId": "a4308306-8623-481e-aa54-20a8556b81c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUWK9AnxXGP-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtAPNLNEd2Cg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EJnL0w_9Njk"
   },
   "source": [
    "## **Curvas de Aprendizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "BAmWhtx5dcpf",
    "outputId": "c879516b-c54c-435d-8462-e33a3135ed76"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for estilo, largura_traco, grau_polinomio in ((\"g-\", 1, 300), (\"b--\", 2, 2), (\"r-+\", 2, 1)):\n",
    "    polybig_features = PolynomialFeatures(degree=grau_polinomio, include_bias=False)\n",
    "    std_scaler = StandardScaler()\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    poly_reg_pipeline = Pipeline([\n",
    "            (\"poly_features\", polybig_features),\n",
    "            (\"std_scaler\", std_scaler),\n",
    "            (\"lin_reg\", lin_reg),\n",
    "        ])\n",
    "    \n",
    "    poly_reg_pipeline.fit(X, y)\n",
    "    y_newbig = poly_reg_pipeline.predict(X_new)\n",
    "    plt.plot(X_new, y_newbig, estilo, label=str(grau_polinomio), linewidth=largura_traco)\n",
    "\n",
    "plt.plot(X, y, \"b.\", linewidth=3)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "salvar_figura(\"comparacao_graus_polinomial_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TDCzenYOxs6"
   },
   "source": [
    "***Pipeline()***\n",
    "\n",
    "> Existem muitas etapas de transformação de dados que precisam ser executadas na ordem correta. Felizmente, o Scikit-Learn fornece a classe `Pipeline` para ajudar com essas seqüências de transformações.\n",
    "\n",
    "> O construtor do `Pipeline` pede uma lista de pares (nome/estimador), definindo uma sequência de etapas. Todos, exceto o último estimador, devem ser transformadores (ou seja, eles devem ter um método `fit_transform ()`).\n",
    "\n",
    "> Quando chamamos o método `fit()` do pipeline (`poly_reg_pipeline.fit(X_treino, y_treino)`), ele chama os métodos `fit_transform()` sequencialmente em todos os transformadores, passando a saída de cada chamada como parâmetro para a próxima chamada, até atingir o estimador final, para o qual chama apenas o método `fit()` do mesmo.\n",
    "\n",
    "> Para saber um pouco mais, leiam o artigo do Data Hackers [\"Como Usar Pipelines no Scikit-Learn\"](https://medium.com/data-hackers/como-usar-pipelines-no-scikit-learn-1398a4cc6ae9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmDn-HWgM88-"
   },
   "source": [
    "### **Verificando erros do modelo com Validação Cruzada (CV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCkAFn4aafBT"
   },
   "outputs": [],
   "source": [
    "#função verificar erro treino\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RJ-g9OsCAL_d",
    "outputId": "06edcdf6-02ea-4d2c-a42d-f1b94b73d31f"
   },
   "outputs": [],
   "source": [
    "#Verificando o erro no treino do algoritmo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDEJomu4kKoP"
   },
   "outputs": [],
   "source": [
    "#Função verificar erro VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DzjW_jJrAh1s",
    "outputId": "06626a54-c164-488c-b18e-f18b10d1c490"
   },
   "outputs": [],
   "source": [
    "#Validação Cruzada execução\n",
    "\n",
    "#Printando as médias das partições de cada VC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AII7KLSeiiLU"
   },
   "source": [
    "### ***Verificando erros do modelo com Curvas de Aprendizado***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53jltj0f-z-j"
   },
   "outputs": [],
   "source": [
    "#Função das curvas de aprendizado\n",
    "\n",
    "def curvas_aprendizado(modelo, X, y):\n",
    "    X_treino, X_val, y_treino, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    treino_erros, val_erros = [], []\n",
    "    for m in range(1, len(X_treino)):\n",
    "        modelo.fit(X_treino[:m], y_treino[:m])\n",
    "        y_treino_pred = modelo.predict(X_treino[:m])\n",
    "        y_val_pred = modelo.predict(X_val)\n",
    "        treino_erros.append(mean_squared_error(y_treino[:m], y_treino_pred))\n",
    "        val_erros.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    plt.plot(np.sqrt(treino_erros), \"r-+\", linewidth=2, label=\"treino\")\n",
    "    plt.plot(np.sqrt(val_erros), \"b-\", linewidth=3, label=\"validação\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)\n",
    "    plt.xlabel(\"n_treino\", fontsize=14)\n",
    "    plt.ylabel(\"MSE\", fontsize=14)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "7Ij9u6UBtW-1",
    "outputId": "98b22d22-b938-4c43-f179-23385da0a804"
   },
   "outputs": [],
   "source": [
    "#Treinando modelos e plotando curvas de aprendizado\n",
    "#modelo com underfitting\n",
    "\n",
    "grau_polinomio = 1\n",
    "polybig_features = PolynomialFeatures(degree=grau_polinomio, include_bias=False)\n",
    "std_scaler = StandardScaler()\n",
    "lin_reg = LinearRegression()\n",
    "poly_reg_pipeline = Pipeline([\n",
    "        (\"poly_features\", polybig_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "curvas_aprendizado(poly_reg_pipeline, X, y)\n",
    "plt.title(\"Grau: \" + str(grau_polinomio))\n",
    "plt.axis([0, 80, 0, 3])                        \n",
    "salvar_figura(\"curvaAprendizado_underfitting_plot\")   \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "U-sksN4-tSkI",
    "outputId": "b8d91475-0660-4e12-d1f4-00869e21a807"
   },
   "outputs": [],
   "source": [
    "#Treinando modelos e plotando curvas de aprendizado\n",
    "#Modelo com overffiting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "gysTdHemBRLk",
    "outputId": "14a1d955-04f8-4983-eac4-713c8cdff4a4"
   },
   "outputs": [],
   "source": [
    "#Treinando modelos e plotando curvas de aprendizado\n",
    "#Modelo com configuração ideal\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUNzREfyQLdK"
   },
   "source": [
    "## **Regularização**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rs8635HoPZv6"
   },
   "source": [
    "### **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "yeb2ZXimBiOE",
    "outputId": "e65bad59-a067-4eaa-fef0-9b68dfe6b36b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "np.random.seed(42)\n",
    "m = 20\n",
    "X = 3 * np.random.rand(m, 1)\n",
    "y = 1 + 0.5 * X + np.random.randn(m, 1) / 1.5\n",
    "X_new = np.linspace(0, 3, 100).reshape(100, 1)\n",
    "\n",
    "#Função para plotar os gráficos que comparam regressão linear e polinomial com diferentes\n",
    "# lambdas\n",
    "def plot_model(model_class, polynomial, alphas, **model_kargs):\n",
    "    for alpha, style in zip(alphas, (\"b-\", \"g--\", \"r:\")):\n",
    "        model = model_class(alpha, **model_kargs) if alpha > 0 else LinearRegression()\n",
    "        if polynomial:\n",
    "            model = Pipeline([\n",
    "                    (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
    "                    (\"std_scaler\", StandardScaler()),\n",
    "                    (\"regul_reg\", model),\n",
    "                ])\n",
    "        model.fit(X, y)\n",
    "        y_new_regul = model.predict(X_new)\n",
    "        lw = 2 if alpha > 0 else 1\n",
    "        plt.plot(X_new, y_new_regul, style, linewidth=lw, label=r\"$\\lambda = {}$\".format(alpha))\n",
    "    plt.plot(X, y, \"b.\", linewidth=3)\n",
    "    plt.legend(loc=\"upper left\", fontsize=15)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 3, 0, 4])\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plot_model(Ridge, polynomial=False, alphas=(0, 10, 100), random_state=42)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(122)\n",
    "plot_model(Ridge, polynomial=True, alphas=(0, 10**-5, 1), random_state=42)\n",
    "\n",
    "salvar_figura(\"ridge_regression_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IcW_L48sMRDS",
    "outputId": "bbeebc21-dbf7-40ec-e62c-35019a00136d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gx2T2FbSPIC4",
    "outputId": "7f1897d5-39cb-40e8-f568-da33d53359ac"
   },
   "outputs": [],
   "source": [
    "#Com stochastic gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ChVLOBzPTLB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDEqZVnIPyLp"
   },
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "6-iT571oP2uc",
    "outputId": "98477066-18a4-493b-f95f-45a49ec82e75"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plot_model(Lasso, polynomial=False, alphas=(0, 0.1, 1), random_state=42)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(122)\n",
    "plot_model(Lasso, polynomial=True, alphas=(0, 10**-7, 1), tol=1, random_state=42)\n",
    "\n",
    "salvar_figura(\"lasso_regression_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlaTcchXP_wk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItuUhHI1SBoX"
   },
   "source": [
    "### **Elastic Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8Y_rpDeSELm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regressão Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Virginica\")\n",
    "plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 3, -0.02, 1.02])\n",
    "salvar_figura(\"logistic_regression_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.int)\n",
    "\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", C=10**10, random_state=42)\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(2.9, 7, 500).reshape(-1, 1),\n",
    "        np.linspace(0.8, 2.7, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "\n",
    "zz = y_proba[:, 1].reshape(x0.shape)\n",
    "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "\n",
    "\n",
    "left_right = np.array([2.9, 7])\n",
    "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
    "\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "plt.text(3.5, 1.5, \"Not Iris-Virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
    "plt.text(6.5, 2.3, \"Iris-Virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.axis([2.9, 7, 0.8, 2.7])\n",
    "salvar_figura(\"logistic_regression_contour_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Aula04_regressao_exemplos_pt2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
